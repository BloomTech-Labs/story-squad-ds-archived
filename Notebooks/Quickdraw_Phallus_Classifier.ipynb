{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw_uze8k5x0p",
        "colab_type": "text"
      },
      "source": [
        "# 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3aAmTdstulu",
        "colab_type": "code",
        "outputId": "7e082a81-7fc5-4366-8a95-25bdb7fe6f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# mount google drive to store files for reproducibility\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3USj88Fnm0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports \n",
        "import ast\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "from skimage import filters, feature\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzeB4lyToWbC",
        "colab_type": "code",
        "outputId": "b26b1280-ddf3-4776-b891-48bfe005c2d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# get data - you can add more classes here\n",
        "df = pd.read_csv('/content/drive/My Drive/Quickdraw/penis-simplified.csv')\n",
        "df2 = pd.read_csv('/content/drive/My Drive/Quickdraw/airplane.csv')\n",
        "df3 = pd.read_csv('/content/drive/My Drive/Quickdraw/arm.csv')\n",
        "# df4 = pd.read_csv('Quickdraw/asparagus.csv')\n",
        "# df5 = pd.read_csv('Quickdraw/anvil.csv')\n",
        "# df6 = pd.read_csv('Quickdraw/ant.csv')\n",
        "# df7 = pd.read_csv('Quickdraw/animal migration.csv')\n",
        "# df8 = pd.read_csv('Quickdraw/angel.csv')\n",
        "# df9 = pd.read_csv('Quickdraw/alarm clock.csv')\n",
        "# df10 = pd.read_csv('Quickdraw/ambulance.csv')\n",
        "# df11 = pd.read_csv('Quickdraw/apple.csv')\n",
        "\n",
        "\n",
        "# removing images not recognized\n",
        "df2 = df2[df2['recognized'] == True]\n",
        "df3 = df3[df3['recognized'] == True]\n",
        "# df4 = df4[df4['recognized'] == True]\n",
        "# df5 = df5[df5['recognized'] == True]\n",
        "# df6 = df6[df6['recognized'] == True]\n",
        "# df7 = df7[df7['recognized'] == True]\n",
        "# df8 = df8[df8['recognized'] == True]\n",
        "# df9 = df9[df9['recognized'] == True]\n",
        "# df10 = df10[df10['recognized'] == True]\n",
        "# df11 = df11[df11['recognized'] == True]\n",
        "\n",
        "# taking 10,000 samples to match size of the penis dataset to avoid \n",
        "# class imbalance\n",
        "df2 = df2[:10000]\n",
        "df3 = df3[:10000]\n",
        "# df4 = df4[:10000]\n",
        "# df5 = df5[:10000]\n",
        "# df6 = df6[:10000]\n",
        "# df7 = df7[:10000]\n",
        "# df8 = df8[:10000]\n",
        "# df9 = df9[:10000]\n",
        "# df10 = df10[:10000]\n",
        "# df11 = df11[:10000]\n",
        "\n",
        "frames = [df, df2, df3] # df4, df5, df6, df7, df8, df9, df10, df11]\n",
        "\n",
        "df4 = pd.concat(frames)\n",
        "print(df4.shape)\n",
        "df4.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29996, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>countrycode</th>\n",
              "      <th>drawing</th>\n",
              "      <th>key_id</th>\n",
              "      <th>recognized</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[79, 80, 90, 97, 112, 125, 137, 171, 183, 18...</td>\n",
              "      <td>2081</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 00:21:52.337000+00:00</td>\n",
              "      <td>penis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[44, 31, 11, 2, 1, 28, 55, 57, 60, 97, 104, ...</td>\n",
              "      <td>2084</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 00:44:05.264000+00:00</td>\n",
              "      <td>penis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[109, 85, 73, 69, 77, 92, 102, 154, 169, 185...</td>\n",
              "      <td>2085</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 01:28:17.250000+00:00</td>\n",
              "      <td>penis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[140, 115, 120, 129, 151, 170, 182, 195, 195...</td>\n",
              "      <td>2087</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 01:29:12.972000+00:00</td>\n",
              "      <td>penis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[88], [111]], [[88], [111]], [[85, 123, 175,...</td>\n",
              "      <td>2088</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 01:37:55.307000+00:00</td>\n",
              "      <td>penis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  countrycode  ...   word\n",
              "0          US  ...  penis\n",
              "1          US  ...  penis\n",
              "2          US  ...  penis\n",
              "3          US  ...  penis\n",
              "4          US  ...  penis\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2V8T9lI6B54",
        "colab_type": "text"
      },
      "source": [
        "# 2. Transform Data\n",
        "The drawing column shows timing of strokes for the google quickdraw data.  That needs to be drawn and converted into an image.  The image then needs to be converted in a numpy array for input into the convolutional neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N2Lqqmiocu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create numpy arrays, 64x64 runs faster than 128x128 without \n",
        "# sacrificing results\n",
        "imheight, imwidth = 64, 64\n",
        "\n",
        "# faster conversion function taken from kaggle competition notebooks\n",
        "def draw_it(strokes):\n",
        "    image = Image.new(\"P\", (256,256), color=255)\n",
        "    image_draw = ImageDraw.Draw(image)\n",
        "    for stroke in ast.literal_eval(strokes):\n",
        "        for i in range(len(stroke[0])-1):\n",
        "            image_draw.line([stroke[0][i], \n",
        "                             stroke[1][i],\n",
        "                             stroke[0][i+1], \n",
        "                             stroke[1][i+1]],\n",
        "                            fill=0, width=5)\n",
        "    image = image.resize((imheight, imwidth))\n",
        "    img_array = np.array(image)/255.\n",
        "    return img_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCYbG3oApDSA",
        "colab_type": "code",
        "outputId": "8d4016e7-92cb-4e36-8c87-dea3a96b4aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# map numpy arrays to each drawing\n",
        "df4['drawing_np'] = df4['drawing'].map(draw_it)\n",
        "df4.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>countrycode</th>\n",
              "      <th>drawing</th>\n",
              "      <th>key_id</th>\n",
              "      <th>recognized</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>word</th>\n",
              "      <th>drawing_np</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[79, 80, 90, 97, 112, 125, 137, 171, 183, 18...</td>\n",
              "      <td>2081</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 00:21:52.337000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[44, 31, 11, 2, 1, 28, 55, 57, 60, 97, 104, ...</td>\n",
              "      <td>2084</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 00:44:05.264000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[109, 85, 73, 69, 77, 92, 102, 154, 169, 185...</td>\n",
              "      <td>2085</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 01:28:17.250000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[140, 115, 120, 129, 151, 170, 182, 195, 195...</td>\n",
              "      <td>2087</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 01:29:12.972000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>[[[88], [111]], [[88], [111]], [[85, 123, 175,...</td>\n",
              "      <td>2088</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-09 01:37:55.307000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  countrycode  ...                                         drawing_np\n",
              "0          US  ...  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "1          US  ...  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "2          US  ...  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "3          US  ...  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "4          US  ...  [[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8LqX8UxpE3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get data in right format\n",
        "X_upright = df4['drawing_np'].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vPRbYrIpIyM",
        "colab_type": "code",
        "outputId": "c839f21e-d29d-4217-9e9c-979a0a772787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "# visualize the first image\n",
        "IMG_SIZE = 64\n",
        "img_array = X_upright[0]\n",
        "img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "plt.imshow(img_array, cmap='gray')\n",
        "plt.axis('off');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAEhUlEQVR4nO3d0W6bQBRAQVz1/385faxjxRgTWA5m5rVSRRwf3d2w2Levr68J6Plz9AUAPxMnRIkTosQJUeKEqL8v/t2fck/sdrsdfQkvuVswTdM0/fiLMjkhSpwQ9WpZy8nMLWWLS8jH6y1e41FMTogSJ0SJE6LsOT/As33mGfdv9z/LGa9/SyYnRIkToixrT+iTbj88XvsZTjWNYnJClDghSpwQZc95EvZi12NyQpQ4IcqyNupsT5ewPZMTosQJUZa1IZay3139ELzJCVHihChxQpQ9Z9QV91h8Z3JClDghyrL2YA6084zJCVHihChxQpQ9Z4jbJ9wzOSFKnBBlWTuYWycsZXJClDghyrL2YP5CyzMmJ0SJE6LECVH2nAO4fcIaJidEiROiLGsHc+uEpUxOiBInRIkTouw5d+DWCVswOSFKnBAlTogSJ0SJE6L8tXYAp4JYw+SEKHFClDghSpwQJU6IEidEuZWyEYfd2ZrJCVHihChxQpQ95w4c12MLJidEiROixAlR4oQocUKUOCFKnBAlTogSJ0Q5IfQLnkRhTyYnRIkToixrN+Kw+/au/pqanBAlTogSJ0TZc3Iot6OeMzkhSpwQJU6IEidEiROixAlR4oQocUKUOCHKCaE3OM3CSCYnRIkTosQJUeKEKHFClDghyq2UX7j6B1DtwWv6n8kJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCHKwfcXfG4QRzE5IUqcECVOiBInRIkTosQJUW6lMJzbU8uYnBAlTogSJ0Ttsucs7il8HmrT3O+l+D6apnHvJZMTosQJUYuXtdUlxlJbXL+l8f6e/Z5Kr/2oazQ5IUqcEDW7rL0f36VlxZ7Ovnw/m8fX+wzvs/trvL/+rX8WkxOixAlR4oQoT6VwqDPsMecsPeG05uc0OSFKnBBlWfvgcfnh1gpbWHObxeSEKHFClDghyp7zDWc8alZ0ldft2TG/pUxOiBInRFnWvnCVJRhjLTk9ZHJClDghyrIWBlhz8szkhChxQpQ4IUqcECVOiBInRK3+OgYnZ2BfJidEiROixAlRs3vO3z4sCqxnckKUOCFq9VMpV/x6QBjJ5IQocUKUOCFKnBAlTogSJ0QtvpUy9wFFnliB7ZmcECVOiFp9Qmhu6er0EHznm63hg4gTosQJUbt8V8qzh7TtP7mS335AgckJUeKEqN2/AnDuc4gsc/kkc8vYNe91kxOixAlR4oSooV87/85Xb9uPcgZ7vodNTogSJ0QNXdY+Wvpkyxb/H6y19L249fvP5IQocULUocvaOWuWCJVvQrO8Pp933jujfr8mJ0SJE6LECVG3F+tnm6eF1u537U/3dZLfy48XaXJClDghyrJ2sJG3e66yZC7eBnmTZS2ciTghSpwQlT2+96lG7nkqxxlHi+4r32ZyQpQ4Icqy9oN9yvLuqkxOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD16mHra34IDQSYnBAlTogSJ0SJE6LECVHihKh/Q6zgBUozlFUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIK_TxOMpTFS",
        "colab_type": "code",
        "outputId": "d4d14bb9-e906-4467-89dd-15057c200566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# shuffle data\n",
        "df4 = df4.sample(frac=1, random_state=42)\n",
        "df4 = df4.reset_index()\n",
        "df4.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>countrycode</th>\n",
              "      <th>drawing</th>\n",
              "      <th>key_id</th>\n",
              "      <th>recognized</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>word</th>\n",
              "      <th>drawing_np</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2308</td>\n",
              "      <td>US</td>\n",
              "      <td>[[[90, 40, 21, 5, 2, 0, 7, 40, 71, 117, 135, 1...</td>\n",
              "      <td>4872</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-18 01:43:00.232000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7759</td>\n",
              "      <td>ES</td>\n",
              "      <td>[[[55, 64, 69, 84, 100, 110, 118, 118, 104, 10...</td>\n",
              "      <td>12574</td>\n",
              "      <td>True</td>\n",
              "      <td>2019-03-04 14:40:59.641000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5226</td>\n",
              "      <td>GB</td>\n",
              "      <td>[[[255, 241, 226, 217, 199, 190, 178, 171, 150...</td>\n",
              "      <td>5291422213210112</td>\n",
              "      <td>True</td>\n",
              "      <td>2017-03-21 17:48:05.150490</td>\n",
              "      <td>arm</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7047</td>\n",
              "      <td>BE</td>\n",
              "      <td>[[[61, 91, 118, 146, 179, 229, 251, 255, 243, ...</td>\n",
              "      <td>11637</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-11-23 11:04:20.827000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2664</td>\n",
              "      <td>CA</td>\n",
              "      <td>[[[0, 43, 88], [173, 124, 79]], [[88, 81, 83, ...</td>\n",
              "      <td>5307</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-18 12:32:27.940000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index countrycode  ...   word                                         drawing_np\n",
              "0   2308          US  ...  penis  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "1   7759          ES  ...  penis  [[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "2   5226          GB  ...    arm  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "3   7047          BE  ...  penis  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "4   2664          CA  ...  penis  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POsfue7dpUnA",
        "colab_type": "code",
        "outputId": "e726974b-b190-403c-d0aa-ccdd0e7dadfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# label target\n",
        "df4['target'] = [1 if x == 'penis' else 0 for x in df4['word']]\n",
        "df4.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>countrycode</th>\n",
              "      <th>drawing</th>\n",
              "      <th>key_id</th>\n",
              "      <th>recognized</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>word</th>\n",
              "      <th>drawing_np</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2308</td>\n",
              "      <td>US</td>\n",
              "      <td>[[[90, 40, 21, 5, 2, 0, 7, 40, 71, 117, 135, 1...</td>\n",
              "      <td>4872</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-18 01:43:00.232000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7759</td>\n",
              "      <td>ES</td>\n",
              "      <td>[[[55, 64, 69, 84, 100, 110, 118, 118, 104, 10...</td>\n",
              "      <td>12574</td>\n",
              "      <td>True</td>\n",
              "      <td>2019-03-04 14:40:59.641000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5226</td>\n",
              "      <td>GB</td>\n",
              "      <td>[[[255, 241, 226, 217, 199, 190, 178, 171, 150...</td>\n",
              "      <td>5291422213210112</td>\n",
              "      <td>True</td>\n",
              "      <td>2017-03-21 17:48:05.150490</td>\n",
              "      <td>arm</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7047</td>\n",
              "      <td>BE</td>\n",
              "      <td>[[[61, 91, 118, 146, 179, 229, 251, 255, 243, ...</td>\n",
              "      <td>11637</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-11-23 11:04:20.827000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2664</td>\n",
              "      <td>CA</td>\n",
              "      <td>[[[0, 43, 88], [173, 124, 79]], [[88, 81, 83, ...</td>\n",
              "      <td>5307</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-10-18 12:32:27.940000+00:00</td>\n",
              "      <td>penis</td>\n",
              "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index countrycode  ...                                         drawing_np  target\n",
              "0   2308          US  ...  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...       1\n",
              "1   7759          ES  ...  [[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...       1\n",
              "2   5226          GB  ...  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...       0\n",
              "3   7047          BE  ...  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...       1\n",
              "4   2664          CA  ...  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...       1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExpE19hlpXyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get data in right format\n",
        "X = df4['drawing_np'].to_list()\n",
        "X = np.array(X).reshape(-1, imheight, imwidth, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOMX9eABpZpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert target to list\n",
        "y = df4['target'].to_list()\n",
        "y = np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj0xkUKLpa9r",
        "colab_type": "code",
        "outputId": "010c2a86-7142-40a4-ab23-8736ac4ea5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHLeA6X0pcMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXkMK0CQpdfW",
        "colab_type": "code",
        "outputId": "30082f49-bd1a-4de6-f416-591108cc2976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23996, 6000, 23996, 6000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZXufCBupe8k",
        "colab_type": "code",
        "outputId": "07769afc-da7c-45cd-edb0-4ac1cd852dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# how many target variables are in the test set?\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "\n",
        "table = np.asarray((unique, np.rint(counts))).T\n",
        "print(table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.000e+00 3.997e+03]\n",
            " [1.000e+00 2.003e+03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS5Wos4epgQn",
        "colab_type": "code",
        "outputId": "d2576c4a-d448-4707-9cd1-86abead683d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23996, 64, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDZeRSsK6Qq_",
        "colab_type": "text"
      },
      "source": [
        "# 3. Train Model\n",
        "The parameters of the model were chosen through trial and error and hyperparameter tuning.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slmVVBqlpiQu",
        "colab_type": "code",
        "outputId": "e8f2fb13-8e9e-4800-fa73-4b2cc6e59dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "# convolutional neural network\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape = X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(128, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(1)) # change to number of classes\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 62, 62, 64)        640       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 29, 29, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 29, 29, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 64)        73792     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                147520    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 295,873\n",
            "Trainable params: 295,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GMUx5ctpjwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiOohw98pmSn",
        "colab_type": "code",
        "outputId": "2b0887e6-51f1-4bc2-ddef-cf985eaeeceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# fit model\n",
        "model.fit(X_train, y_train, batch_size=20, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "960/960 [==============================] - 15s 15ms/step - loss: 0.3203 - accuracy: 0.8589 - val_loss: 0.2097 - val_accuracy: 0.9179\n",
            "Epoch 2/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.1696 - accuracy: 0.9333 - val_loss: 0.1494 - val_accuracy: 0.9429\n",
            "Epoch 3/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.1285 - accuracy: 0.9502 - val_loss: 0.1463 - val_accuracy: 0.9417\n",
            "Epoch 4/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.1023 - accuracy: 0.9604 - val_loss: 0.1243 - val_accuracy: 0.9508\n",
            "Epoch 5/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.0812 - accuracy: 0.9688 - val_loss: 0.1082 - val_accuracy: 0.9588\n",
            "Epoch 6/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.0642 - accuracy: 0.9758 - val_loss: 0.1243 - val_accuracy: 0.9610\n",
            "Epoch 7/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.0504 - accuracy: 0.9821 - val_loss: 0.1590 - val_accuracy: 0.9527\n",
            "Epoch 8/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.0411 - accuracy: 0.9841 - val_loss: 0.1556 - val_accuracy: 0.9521\n",
            "Epoch 9/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.0343 - accuracy: 0.9870 - val_loss: 0.1432 - val_accuracy: 0.9585\n",
            "Epoch 10/10\n",
            "960/960 [==============================] - 14s 15ms/step - loss: 0.0286 - accuracy: 0.9886 - val_loss: 0.1742 - val_accuracy: 0.9567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68f05c69e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts3KiJ0A6Wao",
        "colab_type": "text"
      },
      "source": [
        "# 4. Test Model\n",
        "The model works well (95% accuracy) on data similar to the training data.  The model had difficulty generalizing on hand drawn images.  The training images are drawn with a mouse on a plain white background.  The real world test data are pictures of images drawn on paper with different angles, shadows, brightness, backgrounds; lined paper, blank paper, colored paper etc.  Improvements were made by making test images look like the training images by removing the background, and connecting broken/dotted lines by making the lines thicker.  In our object detection notebook we tried to make the training data look more like the test data through creating our own dataset by drawing images and image augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yG5TY6Q678u",
        "colab_type": "code",
        "outputId": "c0130f19-be76-4bfa-ad6a-27daea065768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# evaluate model on test data\n",
        "print('\\n# Evaluate on test data')\n",
        "results = model.evaluate(X_test, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "47/47 [==============================] - 1s 21ms/step - loss: 0.1908 - accuracy: 0.9552\n",
            "test loss, test acc: [0.19084306061267853, 0.9551666378974915]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8fk2hJ0rzk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function that prints model predicts penis if prediction > .5\n",
        "def show_pred(prediction):\n",
        "    if prediction[0] > .5:\n",
        "        print('Model predicts penis')\n",
        "    else:\n",
        "        print('Model predicts not penis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRh7WjZ9rzna",
        "colab_type": "code",
        "outputId": "288b2aa7-efb7-49f9-9f99-8c39390d8e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# test hand drawn images with model\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 64\n",
        "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    # denoise the background\n",
        "    img_array = cv2.fastNlMeansDenoising(img_array, None, 10, 7, 21)\n",
        "    # remove the background to make it look more like the training data\n",
        "    img_array = cv2.adaptiveThreshold(img_array, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                      cv2.THRESH_BINARY,11,2)\n",
        "    # make lines thicker with erosion to connect broken lines\n",
        "    kernel = np.ones((8,8),np.uint8)\n",
        "    img_array = cv2.erode(img_array, kernel, iterations=1)\n",
        "    # resize\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "    plt.imshow(new_array, cmap='gray')\n",
        "    new_array = new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    return new_array\n",
        "\n",
        "# change to path of image NOT in training data, like an actual drawing on paper\n",
        "filepath = '/content/drive/My Drive/phallic-paper-background/IMG_2298.jpg'\n",
        "\n",
        "prediction = model.predict([prepare(filepath)])\n",
        "\n",
        "print(prediction[0])\n",
        "\n",
        "show_pred(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.]\n",
            "Model predicts not penis\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HERp2rq9rzpc",
        "colab_type": "code",
        "outputId": "fca07447-5937-4d5b-bd98-bee5573a9170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "# iterates over files in test image directory to automate testing\n",
        "# on phallic images only! - shows recall\n",
        "\n",
        "# change directory to one containing images\n",
        "directory = '/content/drive/My Drive/phallic-paper-background'\n",
        "\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 64\n",
        "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    # denoise the background\n",
        "    img_array = cv2.fastNlMeansDenoising(img_array, None, 10, 7, 21)\n",
        "    # remove the background to make it look more like the training data\n",
        "    img_array = cv2.adaptiveThreshold(img_array, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                      cv2.THRESH_BINARY,11,2)\n",
        "    # make lines thicker with erosion to connect broken lines\n",
        "    kernel = np.ones((8,8),np.uint8)\n",
        "    img_array = cv2.erode(img_array, kernel, iterations=1)\n",
        "    # resize\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "    plt.imshow(new_array, cmap='gray')\n",
        "    new_array = new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    return new_array\n",
        "\n",
        "pred_list = []\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
        "        filepath = directory + '/' + filename\n",
        "        prediction = model.predict([prepare(filepath)])\n",
        "        pred_list.append(np.rint(prediction[0]))\n",
        "    else:\n",
        "        pass\n",
        "    \n",
        "tp = pred_list.count(1)\n",
        "fn = pred_list.count(0)\n",
        "\n",
        "recall = tp / (tp + fn)\n",
        "recall = round(recall, 2)\n",
        "\n",
        "print('True Positive:', tp)\n",
        "print('False Negative:', fn)\n",
        "print('Recall:', str(recall) + '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive: 21\n",
            "False Negative: 17\n",
            "Recall: 0.55%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARX0lEQVR4nO3dbYxc1X3H8e8vJjZuQBjC4jhew1KBgixUr2EwtkDIMQ+xKYK8QIATVVZlyciiFVFTBdNKDanaAG9CEqlyYhWKXyS2yQM1sgLBmIe6yDwM2IQHx8GhRrZlswvCCVRxwMm/L+Z6srPd9d6duXdmds/vI63mnPsw96+d/e85994z5yoiMLPJ7xOdDsDM2sPJbpYIJ7tZIpzsZolwspslwsluloiWkl3SUkl7JO2VtKaooMyseGr2PrukKcCvgKuBA8CLwPKIeKO48MysKCe1sO8CYG9EvAUgaSNwAzBqsp955pnR19fXwiHN7ET27dvHu+++q5HWtZLss4H9Q+oHgEtPtENfXx/VarWFQ5rZiVQqlVHXlX6BTtIqSVVJ1cHBwbIPZ2ajaCXZDwJzhtR7s2UNImJdRFQiotLT09PC4cysFa0k+4vA+ZLOlTQVuAV4pJiwzKxoTZ+zR8QxSX8D/ByYAjwQEa8XFpmZFaqVC3RExM+AnxUUi5mVyCPozBLhZDdLhJPdLBFOdrNEONnNEuFkN0uEk90sEU52s0Q42c0S4WQ3S4ST3SwRTnazRDjZzRLR0rfebOKSRpym7IQGBgYa6p6MZGJxy26WCCe7WSKc7GaJ8Dl7Ipo5Rx/urLPOaqg3+4AR6wy37GaJcLKbJcLd+EmsiK77iWzcuLFevuWWW0o9lrXOLbtZIpzsZolwspslwufsk8yHH3447n3OOeechvrbb7+da7/ly5fXyz5n735jtuySHpA0IOm1IcvOkLRV0pvZ6+nlhmlmrcrTjX8QWDps2RpgW0ScD2zL6mbWxcbsxkfEf0nqG7b4BmBxVl4PPA3cUWBc1qRTTz113Pvs27dv1HVl376z9mn2At3MiDiUlQ8DMwuKx8xK0vLV+KgNkB51kLSkVZKqkqqDg4OtHs7MmtTs1fh3JM2KiEOSZgEDo20YEeuAdQCVSsXfnOgSeb/EkneU3GOPPdZQX7p0+GUe67RmW/ZHgBVZeQWwuZhwzKwseW69bQB2AJ+TdEDSSuAe4GpJbwJXZXUz62J5rsYvH2XVlQXHYmYl8gi6Ce7w4cO5tuvt7W3q/W+++eZ62aPkJjaPjTdLhJPdLBHuxk9ws2bNyrXd/v37S41j2bJlDXXPT9d93LKbJcLJbpYIJ7tZIpzsZolwspslwslulgjfepvEFi5cWOj73XrrrQ3173//+4W+v5XLLbtZIpzsZolwN34S27FjR6Hvd/311zfU3Y2fWNyymyXCyW6WCCe7WSJ8zj4BHT16tCPHvfbaaztyXCuGW3azRDjZzRLhZDdLhJPdLBFOdrNEONnNEuFbbxPQ9OnTOx2CTUB5Hv80R9JTkt6Q9Lqk27PlZ0jaKunN7PX08sM1s2bl6cYfA74aEXOBhcBtkuYCa4BtEXE+sC2rm1mXGjPZI+JQRLyclT8AdgOzgRuA9dlm64EvlhWkmbVuXBfoJPUB84HngZkRcShbdRiYWWhkZlao3Mku6RTgJ8BXIuK3Q9dF7fEfIz4CRNIqSVVJ1cHBwZaCNbPm5Up2SZ+klug/iIifZovfkTQrWz8LGBhp34hYFxGViKj09PQUEbOZNWHMW2+SBNwP7I6Ibw1Z9QiwArgne91cSoQ2LhdccEGnQ7Aulec++2XAXwGvStqVLfsHakn+kKSVwNvATeWEaGZFGDPZI+K/AY2y+spiwzGzsngE3SSzdu3aTodgXcpj480S4WQ3S4S78ZPM4sWLOx2CdSm37GaJcLKbJcLJbpYIn7PbhHDxxRfXyy+//PKo2339619vqN91111lhTThuGU3S4ST3SwR7sZb13rvvffq5RN13Yfas2dPWeFMeG7ZzRLhZDdLhJPdLBE+Z58AUp0n/uOPPx73Po8++mhDvTb3ythqM6tNbm7ZzRLhZDdLhLvxE1y3TuKZt/t83nnnjbpu+/bt4z7ub37zm3HvA7Bhw4Z6efny5U29R7dzy26WCCe7WSLcjZ8Ajh49Ouq6KVOmtDGS4u3du7fTIQDNd/8nErfsZolwspslwslulgifs1tuq1ev7nQI1oIxW3ZJJ0t6QdIrkl6X9I1s+bmSnpe0V9ImSVPLD9fMmpWnG/97YElEzAP6gaWSFgL3AvdFxHnA+8DK8sI0s1bledZbAB9m1U9mPwEsAb6ULV8P3AX42UNtdujQobYdq+wvi3zwwQcN9VNOOaWp/Zoxbdq0lt+j2+V9PvuU7AmuA8BW4NfAkYg4lm1yAJhdTohmVoRcyR4Rf4iIfqAXWADkfgi4pFWSqpKqg4ODTYZpZq0a1623iDgCPAUsAmZIOn4a0AscHGWfdRFRiYhKt35pwywFY56zS+oBPo6II5KmA1dTuzj3FHAjsBFYAWwuM1Cb/E50jp7C5BJly3OffRawXtIUaj2BhyJii6Q3gI2S/gXYCdxfYpxm1qI8V+N/AcwfYflb1M7fzWwC8Ag6K4W73d3HY+PNEuFkN0uEk90sEU52s0Q42c0S4WQ3S4RvvVlueeeCt+7klt0sEU52s0Q42c0S4WQ3S4ST3SwRTnazRDjZzRLhZDdLhJPdLBFOdrNEONnNEuFkN0uEvwhjua1d2/h0r+9973ujbrt79+56ee7cubnef+rUxmeDvvDCC/XyvHnzcr2Hjc4tu1kinOxmiXCymyXC5+wl8CQP+c/Th/roo48a6v39/fVytVqtly+++OLmA0tY7pY9e2zzTklbsvq5kp6XtFfSJklTx3oPM+uc8XTjbwd2D6nfC9wXEecB7wMriwzMzIqVqxsvqRf4S+Bfgb9TrZ+6BPhStsl64C5g7YhvMMm5216+SqVSLw+9JQdwySWXtDucCSlvy/5t4GvAH7P6p4EjEXEsqx8AZhccm5kVaMxkl3QdMBARLzVzAEmrJFUlVQcHB5t5CzMrQJ6W/TLgekn7gI3Uuu/fAWZIOn4a0AscHGnniFgXEZWIqPT09BQQspk1I8/z2e8E7gSQtBj4+4j4sqQfATdS+wewAthcYpxdp4jz9Msuu6yh/uyzz7b8nt3uuuuuG3Xdli1bcr3HggULGup+PHQ+rQyquYPaxbq91M7h7y8mJDMrw7gG1UTE08DTWfktYMGJtjez7uERdONwom95jebSSy9tqD/33HO59ps+fXq9fPTo0YZ1J5988rjj6KT9+/fXy729vaNuN3wE3bRp03K9//z58+vlnTt3jjO6dHhsvFkinOxmiXA3fhxWr1497n3ydtuH+93vftfUft1i6dKl9fKJuu5DDZ+84siRI/XyjBkzRt1v165d44wuTW7ZzRLhZDdLhJPdLBE+Zy+BR3TBo48+2vJ7nHbaaePe58knn2yoL1mypOU4Jgu37GaJcLKbJcLd+BPYuHFjru3uvvvukiOxw4cP18uf+cxnRt1u3bp1DXV34//ELbtZIpzsZolwspslwufsBVizZk2nQ+iIdt5inDlzZq7tNm3a1FDPe90lBW7ZzRLhZDdLhJPdLBFOdrNEONnNEuGr8U264447Oh1Csnbs2NFQX7RoUYcimVjcspslwslulggnu1kifM7epHvvvbdevueeezoYSXq++93vdjqECSnv89n3AR8AfwCORURF0hnAJqAP2AfcFBHvlxOmmbVqPN34z0dEf0RUsvoaYFtEnA9sy+pm1qVa6cbfACzOyuupPQPO96OsdBs2bOh0CBNS3pY9gMclvSRpVbZsZkQcysqHgXxfSzKzjsjbsl8eEQclnQVslfTLoSsjIiSN+H3H7J/DKoCzzz67pWDNrHm5WvaIOJi9DgAPU3tU8zuSZgFkrwOj7LsuIioRUenp6SkmajMbtzFbdkmfAj4RER9k5WuAfwYeAVYA92Svm8sMtJsNnyN92bJlHYrEbr755k6H0LXydONnAg9LOr79DyPiMUkvAg9JWgm8DdxUXphm1qoxkz0i3gLmjbD8PeDKMoIys+KpnfOIVSqVqFarbTte0bLezZj8+Kfi5f3db9++vaF++eWXlxFO16pUKlSr1RF/WR4bb5YIJ7tZIpzsZonwt95K8Pjjj9fL11xzTQcjmdiOHDky7n1SO0cfD7fsZolwspslwt34cVi9enW9vHbt2lG3+8IXvlAvP/PMMw3rrrjiiuIDm6ROP/30XNtddNFFJUcyObhlN0uEk90sER5B16S8I7qGu+qqq+rlrVu3FhXOpNDs79QjFv/EI+jMzMlulgonu1kifOutSfv376+X58yZk3u/J554ol7u7+9vWLdr167WA0uAf0/Ncctulggnu1ki3I1vUm9vb728YsWKhnXr16/P9R6vvPJKQ33orSffTmrU19dXL8+b9/8mTrIc3LKbJcLJbpYIJ7tZInzOXoAHH3ywof7Nb36zXp49e3abo5m4Xn311VHXXXjhhW2MZHJyy26WCCe7WSLcjS/BZz/72Xp5+C20Zr/ZlQJ31cuVq2WXNEPSjyX9UtJuSYsknSFpq6Q3s9d804qYWUfk7cZ/B3gsIi6g9iio3cAaYFtEnA9sy+pm1qXGTHZJpwFXAPcDRMRHEXEEuAE4PlRsPfDFsoKcTCIi149Z0fK07OcCg8B/SNop6d+zRzfPjIhD2TaHqT3t1cy6VJ5kPwm4CFgbEfOB/2VYlz1qTdGIzZGkVZKqkqqDg4OtxmtmTcqT7AeAAxHxfFb/MbXkf0fSLIDsdWCknSNiXURUIqLS09NTRMxm1oQxkz0iDgP7JX0uW3Ql8AbwCHD8614rgM2lRGhmhch7n/1vgR9Imgq8Bfw1tX8UD0laCbwN3FROiGZWhFzJHhG7gMoIq64sNhwzK4uHy5olwslulggnu1kinOxmiXCymyXCyW6WCCe7WSLa+shmSYPUBuCcCbzbtgOPrBtiAMcxnONoNN44zomIEceltzXZ6weVqhEx0iCdpGJwHI6jnXG4G2+WCCe7WSI6lezrOnTcobohBnAcwzmORoXF0ZFzdjNrP3fjzRLR1mSXtFTSHkl7JbVtNlpJD0gakPTakGVtnwpb0hxJT0l6Q9Lrkm7vRCySTpb0gqRXsji+kS0/V9Lz2eezKZu/oHSSpmTzG27pVByS9kl6VdIuSdVsWSf+Rkqbtr1tyS5pCvBvwDJgLrBc0tw2Hf5BYOmwZZ2YCvsY8NWImAssBG7LfgftjuX3wJKImAf0A0slLQTuBe6LiPOA94GVJcdx3O3Upic/rlNxfD4i+ofc6urE30h507bnndq41R9gEfDzIfU7gTvbePw+4LUh9T3ArKw8C9jTrliGxLAZuLqTsQB/BrwMXEpt8MZJI31eJR6/N/sDXgJsAdShOPYBZw5b1tbPBTgN+B+ya2lFx9HObvxsYP+Q+oFsWad0dCpsSX3AfOD5TsSSdZ13UZsodCvwa+BIRBzLNmnX5/Nt4GvAH7P6pzsURwCPS3pJ0qpsWbs/l1KnbfcFOk48FXYZJJ0C/AT4SkT8thOxRMQfIqKfWsu6ALig7GMOJ+k6YCAiXmr3sUdweURcRO008zZJVwxd2abPpaVp28fSzmQ/CMwZUu/NlnVKrqmwiybpk9QS/QcR8dNOxgIQtaf7PEWtuzxD0vF5Cdvx+VwGXC9pH7CRWlf+Ox2Ig4g4mL0OAA9T+wfY7s+lpWnbx9LOZH8ROD+70joVuIXadNSd0vapsFV7hOv9wO6I+FanYpHUI2lGVp5O7brBbmpJf2O74oiIOyOiNyL6qP09PBkRX253HJI+JenU42XgGuA12vy5RNnTtpd94WPYhYZrgV9ROz/8xzYedwNwCPiY2n/PldTODbcBbwJPAGe0IY7LqXXBfgHsyn6ubXcswF8AO7M4XgP+KVv+58ALwF7gR8C0Nn5Gi4EtnYgjO94r2c/rx/82O/Q30g9Us8/mP4HTi4rDI+jMEuELdGaJcLKbJcLJbpYIJ7tZIpzsZolwspslwslulggnu1ki/g/r1H5043jDQQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUm1_MB9yr8U",
        "colab_type": "code",
        "outputId": "4b48e297-3c92-46ec-c9dc-782885222a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "# iterates over files in test image directory to automate testing\n",
        "# on non-phallic images only! shows specificity\n",
        "\n",
        "# change directory to one containing images\n",
        "directory = '/content/drive/My Drive/non-phallic'\n",
        "\n",
        "def prepare(filepath):\n",
        "    IMG_SIZE = 64\n",
        "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "    # denoise the background\n",
        "    img_array = cv2.fastNlMeansDenoising(img_array, None, 10, 7, 21)\n",
        "    # remove the background to make it look more like the training data\n",
        "    img_array = cv2.adaptiveThreshold(img_array, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                      cv2.THRESH_BINARY,11,2)\n",
        "    # make lines thicker with erosion to connect broken lines\n",
        "    kernel = np.ones((8,8),np.uint8)\n",
        "    img_array = cv2.erode(img_array, kernel, iterations=1)\n",
        "    # resize\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "    plt.imshow(new_array, cmap='gray')\n",
        "    new_array = new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    return new_array\n",
        "\n",
        "pred_list = []\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
        "        filepath = directory + '/' + filename\n",
        "        prediction = model.predict([prepare(filepath)])\n",
        "        pred_list.append(np.rint(prediction[0]))\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "fp = pred_list.count(1)\n",
        "tn = pred_list.count(0)\n",
        "\n",
        "specificity =  tn / (tn + fp)\n",
        "specificity = round(specificity, 2)\n",
        "\n",
        "print('False Positive:', fp)\n",
        "print('True Negative:', tn)\n",
        "print('Specificity', str(specificity) + '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive: 4\n",
            "True Negative: 29\n",
            "Specificity 0.88%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jM0camry7KC",
        "colab_type": "code",
        "outputId": "d2124abd-208d-4f8d-f2ba-b0769c364fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# accuracy calculation for all drawings \n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "accuracy = round(accuracy, 2)\n",
        "print('Accuracy:', str(accuracy) + '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFFkGAOS3zOH",
        "colab_type": "code",
        "outputId": "d4476083-86ff-4d82-dba2-0db264153a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# save model for later use\n",
        "model.save('/content/drive/My Drive/64x64-Airplane-Arm-70.model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/64x64-Airplane-Arm-70.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Quickdraw Phallus Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}